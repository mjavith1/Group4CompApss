{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_cleaned' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32m<timed exec>:11\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
          ]
        }
      ],
      "source": [
        "%%time  \n",
        "import gc\n",
        "from sklearn.metrics import mean_squared_error  \n",
        "from sklearn.model_selection import train_test_split  \n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "from keras.models import Sequential  \n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "\n",
        "X = df_cleaned.drop(columns=\"bg+1:00\")  \n",
        "y = df_cleaned['bg+1:00']  \n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ANN model\n",
        "ann_model = Sequential()\n",
        "ann_model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "ann_model.add(Dropout(0.3))  # Dropout for regularization\n",
        "ann_model.add(Dense(32, activation='relu'))\n",
        "ann_model.add(Dropout(0.3))  # Another dropout layer\n",
        "ann_model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "ann_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Early stopping and learning rate scheduler\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "# Clear memory\n",
        "gc.collect()\n",
        "\n",
        "# Train the model with early stopping and learning rate scheduler\n",
        "history = ann_model.fit(X_train_scaled, y_train, epochs=100, batch_size=10, \n",
        "                        validation_split=0.2, callbacks=[early_stopping, lr_scheduler])\n",
        "\n",
        "# Predictions and RMSE calculation  \n",
        "ann_predictions = ann_model.predict(X_test_scaled)  \n",
        "ann_rmse = np.sqrt(mean_squared_error(y_test, ann_predictions))  \n",
        "gc.collect()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
